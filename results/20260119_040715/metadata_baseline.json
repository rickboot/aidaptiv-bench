{
  "timestamp": "2026-01-19T04:07:15.250806",
  "git_commit": "1132df0f3891440a45e71cddb16f81a54787262f",
  "platform": {
    "system": "Darwin",
    "release": "24.3.0",
    "machine": "arm64",
    "cpu_cores": 10,
    "ram_total_gb": 16.0,
    "ram_limit_gb": 12.0,
    "vram_limit_gb": 11.0
  },
  "test_config": {
    "scenario_name": "Llama-8B_1K-128K_2K-step",
    "model": "llama3.1:8b",
    "concurrency": 1,
    "runs_per_context": 1,
    "step_mode": "linear",
    "context_lengths": [
      1024,
      3072,
      5120,
      7168,
      9216,
      11264,
      13312,
      15360,
      17408,
      19456,
      21504,
      23552,
      25600,
      27648,
      29696,
      31744,
      33792,
      35840,
      37888,
      39936,
      41984,
      44032,
      46080,
      48128,
      50176,
      52224,
      54272,
      56320,
      58368,
      60416,
      62464,
      64512,
      66560,
      68608,
      70656,
      72704,
      74752,
      76800,
      78848,
      80896,
      82944,
      84992,
      87040,
      89088,
      91136,
      93184,
      95232,
      97280,
      99328,
      101376,
      103424,
      105472,
      107520,
      109568,
      111616,
      113664,
      115712,
      117760,
      119808,
      121856,
      123904,
      125952,
      128000,
      130048
    ],
    "scenario": "synthetic",
    "max_tokens_output": 50,
    "temperature": 0.0,
    "top_p": 0.9,
    "seed": 42
  },
  "config": {
    "platform": {
      "name": "local_mac_16gb",
      "ram_gb": 12.0,
      "vram_gb": 11.0
    },
    "runtime": {
      "backend": "vllm",
      "endpoint": "http://localhost:11434/v1/completions",
      "model_name": "llama3.1:8b"
    },
    "aidaptiv": {
      "toggle_method": "manual",
      "storage_device": "nvme0n1"
    },
    "test": {
      "context_lengths": [
        1024,
        3072,
        5120,
        7168,
        9216,
        11264,
        13312,
        15360,
        17408,
        19456,
        21504,
        23552,
        25600,
        27648,
        29696,
        31744,
        33792,
        35840,
        37888,
        39936,
        41984,
        44032,
        46080,
        48128,
        50176,
        52224,
        54272,
        56320,
        58368,
        60416,
        62464,
        64512,
        66560,
        68608,
        70656,
        72704,
        74752,
        76800,
        78848,
        80896,
        82944,
        84992,
        87040,
        89088,
        91136,
        93184,
        95232,
        97280,
        99328,
        101376,
        103424,
        105472,
        107520,
        109568,
        111616,
        113664,
        115712,
        117760,
        119808,
        121856,
        123904,
        125952,
        128000,
        130048
      ],
      "concurrency": 1,
      "runs_per_context": 1,
      "warmup_runs": 1,
      "max_tokens_output": 50,
      "temperature": 0.0,
      "top_p": 0.9,
      "seed": 42,
      "timeout_seconds": 300,
      "scenario_name": "Llama-8B_1K-128K_2K-step",
      "step_mode": "linear"
    },
    "telemetry": {
      "sample_interval_sec": 1.0,
      "collect_disk_io": true,
      "output_file": "metrics.csv"
    }
  },
  "runtime_version": "Unknown"
}